{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7fc2319",
   "metadata": {},
   "source": [
    "# Prepare the Dataset for Fine-Tuning Whisper and Wav2Vec2\n",
    "\n",
    "The raw data includes files of two types: \n",
    "\n",
    "1. `.wav` audio of speech by one or more speakers\n",
    "2. `.eaf` (ELAN Annotation Format) transcriptions of speech. [ELAN](https://archive.mpi.nl/tla/elan) = European Distriubted Corpora Project ([EUDICO](https://www.mpi.nl/world/tg/lapp/eudico/eudico.html)) Linguistic Annotator.\n",
    "\n",
    "## Audio Files\n",
    "\n",
    "The audio files can be used as they are, provided that they use the sample rate expected by the model. I'll check that and resample if needed.\n",
    "\n",
    "## Transcription Files\n",
    "\n",
    "The transcription files require some preprocessing. The first step is to manually rename them to match the names of the corresponding `wav` files. \n",
    "\n",
    "The next step is to identify the correct \"tier\" to use. The `eaf` format is a flavor of XML. Fortunately, there is a Python library for reading and parsing ELAN files‚Äî[PymPi](https://github.com/dopefishh/pympi). It will be used here to extract the information needed for fine-tuning.\n",
    "\n",
    "## The Goal\n",
    "\n",
    "The goal is to produce a dataset that looks like this:\n",
    "\n",
    "```json\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"Manolo\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"Manolo Romero\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"aca vivo en Nuevo Union, Pozo Amarillo\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"yo tengo 39 anos\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"si\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"si\"}\n",
    "{\"audio\": \"../new-data/2019-08-16-MR-narracion.wav\", \"text\": \"asma'ak altenama kolha ka\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d83f51",
   "metadata": {},
   "source": [
    "## Load the Libraries\n",
    "\n",
    "The following libraries are required for reading, parsing, formatting, and writing the dataset:\n",
    "\n",
    "- `json`: For writing the dataset to JSON format\n",
    "- `os`: For interacting with the computer's operating system\n",
    "- `pydub`: For working with audio files (<https://github.com/jiaaro/pydub>)\n",
    "- `pympi`: For reading and parsing ELAN files (<https://github.com/dopefishh/pympi>)\n",
    "- `shutil`: For high-level file operations like copying and removing files\n",
    "- `subprocess`: For managing subroutines\n",
    "- `wave`: For reading and writing WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pympi\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "from transformers import WhisperProcessor, WhisperFeatureExtractor\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_dir = '../new-data'\n",
    "output_jsonl = '../new-data/whisper_finetune_dataset.jsonl'\n",
    "output_dir = \"../whisper_finetune_cpu\"\n",
    "log_dir = \"../logs\"\n",
    "\n",
    "# If directories do not exist, create them\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "TRANSCRIPTION_TIERS = [\n",
    "    'transcript_MR', 'Transcript', 'transcript_ER', 'transcript_LF',\n",
    "    'transcript_LM', 'transcript_MM', 'transcript_TF', 'transcript_SSA',\n",
    "    'transcripcion_CA', 'transcript_PA', 'Transcripcion', 'AR_transcripcion',\n",
    "    'transcripcion', 'FF_Transcripcion', 'Transcripcion_FF'\n",
    "]\n",
    "min_duration_sec = 0.5\n",
    "\n",
    "# Find all .eaf files\n",
    "eaf_paths = sorted(glob(os.path.join(data_dir, '*.eaf')))\n",
    "\n",
    "samples = []\n",
    "\n",
    "for eaf_path in eaf_paths:\n",
    "    basename = os.path.splitext(os.path.basename(eaf_path))[0]\n",
    "    wav_path = os.path.join(data_dir, basename + '.wav')\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"‚ö†Ô∏è Missing WAV file for: {basename}\")\n",
    "        continue\n",
    "\n",
    "    eaf = pympi.Elan.Eaf(eaf_path)\n",
    "    tier_names = eaf.get_tier_names()\n",
    "\n",
    "    # Try all known transcription tiers for this file\n",
    "    matching_tiers = [tier for tier in TRANSCRIPTION_TIERS if tier in tier_names]\n",
    "    if not matching_tiers:\n",
    "        print(f\"‚ö†Ô∏è No matching tier in {basename}\")\n",
    "        continue\n",
    "\n",
    "    for tier in matching_tiers:\n",
    "        for start_ms, end_ms, value in eaf.get_annotation_data_for_tier(tier):\n",
    "            duration = (end_ms - start_ms) / 1000.0\n",
    "            if duration < min_duration_sec or not value.strip():\n",
    "                continue\n",
    "            samples.append({\n",
    "                \"audio\": wav_path,\n",
    "                \"start\": start_ms / 1000.0,\n",
    "                \"end\": end_ms / 1000.0,\n",
    "                \"text\": value.strip()\n",
    "            })\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(samples)} segments from {len(eaf_paths)} EAF files.\")\n",
    "\n",
    "# Save to JSONL\n",
    "with open(output_jsonl, 'w', encoding='utf-8') as f:\n",
    "    for sample in samples:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"üìÑ Saved dataset to {output_jsonl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your new JSONL dataset\n",
    "jsonl_path = \"../new-data/whisper_finetune_dataset.jsonl\"\n",
    "\n",
    "# Load the dataset (entire dataset as a single split)\n",
    "dataset = load_dataset(\"json\", data_files=jsonl_path, split=\"train\")\n",
    "\n",
    "# Split into train/validation/test (80/10/10)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=seed)\n",
    "val_test = split_dataset['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "\n",
    "# Assemble into a DatasetDict\n",
    "whisper_dataset = DatasetDict({\n",
    "    \"train\": split_dataset['train'],\n",
    "    \"validation\": val_test['train'],\n",
    "    \"test\": val_test['test']\n",
    "})\n",
    "\n",
    "# Optional: Preview\n",
    "print(whisper_dataset)\n",
    "print(whisper_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_dataset = whisper_dataset.remove_columns([\"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will include both the feature extractor and tokenizer\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "# Make a generic tokenizer\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4665d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_dataset = whisper_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3986fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(whisper_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c196a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43367223",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = EmissionsTracker(\n",
    "    project_name=\"whisper-enenlhet-cpu\",\n",
    "    output_dir=log_dir,\n",
    "    output_file=\"whisper-prepare-data-emissions-cpu.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2568347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start emissions tracking\n",
    "tracker.start()\n",
    "for split in whisper_dataset:\n",
    "    whisper_dataset[split] = whisper_dataset[split].map(\n",
    "        prepare_dataset,\n",
    "        remove_columns=whisper_dataset[split].column_names,\n",
    "        num_proc=4\n",
    "    )\n",
    "# Stop emissions tracking\n",
    "tracker.stop()\n",
    "# Save the processed dataset to disk\n",
    "whisper_dataset.save_to_disk(\"whisper_prepared_dataset\")\n",
    "print(\"‚úÖ Dataset prepared and saved to 'whisper_prepared_dataset' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
