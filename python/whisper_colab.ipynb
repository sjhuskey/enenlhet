{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1733d464",
      "metadata": {
        "id": "1733d464"
      },
      "source": [
        "# Fine-tune Whisper for Enenlhet on Google Colab\n",
        "\n",
        "There are several challenges at the outset:\n",
        "\n",
        "- Whisper is a sprawling, poorly maintained, and brittle ecosystem that has blockers practically built into it\n",
        "- Enenlhet is a low-resource, endangered language, so it doesn't have any pre-built tokenizers or any other items that Whisper models require\n",
        "- Google Colab is unstable and liable to crash or disconnect in the middle of fine-tuning\n",
        "\n",
        "But, I have tried fine-tuning on a CPU, and that was a long nightmare of monkey code and hardware snafus.\n",
        "\n",
        "I'm going to try here to make a notebook that will successfully fine-tune a Whisper model. To do that, I need to:\n",
        "\n",
        "1. Set up the environment properly\n",
        "    a. Install packages\n",
        "    b. Log into the Hugging Face Hub\n",
        "    c. Make sure we're using the GPU\n",
        "    d. Create directories\n",
        "    e. Set a random seed for reproducibility\n",
        "    f. Set the name of the model we'll be fine-tuning.\n",
        "2. Prepare the dataset\n",
        "3. Download and prepare the model\n",
        "4. Set up and initialize a trainer with arguments optimized for GPU\n",
        "5. Set up a `compute_metrics` function to use Word Error Rate to measure the model's performance\n",
        "6. Save the output\n",
        "7. Upload the model to Hugging Face Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e99d1b",
      "metadata": {
        "id": "68e99d1b"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "### Install and import packages\n",
        "\n",
        "Several packages are not installed by default on Google Colab, so they must be added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c953ae09",
      "metadata": {
        "id": "c953ae09"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install --quiet transformers datasets accelerate evaluate huggingface_hub codecarbon jiwer --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6MWrD0fAJ5Nl",
      "metadata": {
        "id": "6MWrD0fAJ5Nl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "from codecarbon import EmissionsTracker\n",
        "from glob import glob\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from datasets import (\n",
        "    Audio,\n",
        "    Dataset,\n",
        "    DatasetDict,\n",
        "    load_dataset\n",
        ")\n",
        "import evaluate\n",
        "from huggingface_hub import snapshot_download, notebook_login\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from transformers import (\n",
        "    EarlyStoppingCallback,\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperTokenizer\n",
        ")\n",
        "from transformers.trainer_seq2seq import Seq2SeqTrainer\n",
        "from transformers.training_args_seq2seq import Seq2SeqTrainingArguments\n",
        "from typing import Any, Dict, List, Union"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311a6816",
      "metadata": {
        "id": "311a6816"
      },
      "source": [
        "### Log into the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7a96ee7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "d251704da7eb483aa7c3b7a6a65d07e9",
            "612960362b3040c3888c34a02f79b485",
            "18d0ddebc22c42d984011e7bd5f586ca",
            "16a5184995244501a5af53654ac1023f",
            "a63ed8d1ce80420dbb1a40933346b1db",
            "ffadd20e604a4a94b6b55b77f8a11f5f",
            "b8ff8e3a255b40e7971c63e4fd6f4426",
            "3919b5b6ac684c8ea3344fed966f3718",
            "fe6598d93de4429d810b0a5adbc864b9",
            "f7269a56b17c456f995be215718b8fed",
            "a3c4bad0fbd6405f804a64a4bfe01899",
            "64acfdfac90d4146a9d8843d5f21cda3",
            "e3b40c7086d341658d3b6f6939f34aef",
            "cf86c92da8f141098d03804b9d6c9185",
            "524e1f736bd84a25bc226f94f5aab279",
            "90dc5091affe44aaaf8a411eebe66e3a",
            "0a8c9e0743a84443a8780787501e5daa"
          ]
        },
        "id": "7a96ee7a",
        "outputId": "4477eefb-b06d-42ff-d9f7-984158dfd28c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d251704da7eb483aa7c3b7a6a65d07e9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Authenticate with Hugging Face Hub\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c1a582",
      "metadata": {
        "id": "d6c1a582"
      },
      "source": [
        "### Make sure that we're using a GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e367246c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e367246c",
        "outputId": "4c933717-2c4f-454c-a2ff-bad21456456d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"GPU is not available. Please enable GPU in 'Runtime > Change runtime type'.\")\n",
        "else:\n",
        "    print(\"GPU is available:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9200169d",
      "metadata": {
        "id": "9200169d"
      },
      "source": [
        "### Create directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7ac2e3f0",
      "metadata": {
        "id": "7ac2e3f0"
      },
      "outputs": [],
      "source": [
        "# Create necessary directories\n",
        "output_dir = \"./enenlhet-whisper-model\"\n",
        "log_dir = \"./logs\"\n",
        "dataset_dir = \"./enenlhet-dataset\"\n",
        "\n",
        "# If directories do not exist, create them\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "os.makedirs(dataset_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cafb430",
      "metadata": {
        "id": "7cafb430"
      },
      "source": [
        "### Set a random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "51707b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51707b67",
        "outputId": "69ce03dc-9f7d-4ac6-b499-4424c78eeec5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b1a80abfcb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90e1a3c",
      "metadata": {
        "id": "b90e1a3c"
      },
      "source": [
        "### Set the model_name variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "999b0b47",
      "metadata": {
        "id": "999b0b47"
      },
      "source": [
        "### Download the dataset\n",
        "\n",
        "First I'll use `snapshot_download()` to download the content of the dataset repository."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_dataset = load_dataset(\"enenlhet-asr/enenlhet-whisper-dataset\")\n",
        "# Ensure PyTorch tensors are returned\n",
        "# whisper_dataset[\"train\"].set_format(type=\"torch\", columns=[\"input_features\", \"attention_mask\", \"labels\"])\n",
        "# whisper_dataset[\"validation\"].set_format(type=\"torch\", columns=[\"input_features\", \"attention_mask\", \"labels\"])\n",
        "# whisper_dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_features\", \"attention_mask\", \"labels\"])\n",
        "# Use only the first 100 samples from the training set\n",
        "# whisper_dataset[\"train\"] = whisper_dataset[\"train\"].select(range(100))\n",
        "# whisper_dataset[\"validation\"] = whisper_dataset[\"validation\"].select(range(50))\n",
        "# whisper_dataset[\"test\"] = whisper_dataset[\"test\"].select(range(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I-ay7b1gHPn",
        "outputId": "a70bb6d5-afbb-44de-b9ae-8a3a4701e525"
      },
      "id": "0I-ay7b1gHPn",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Collect all label lengths from the training set\n",
        "# label_lengths = [len(example[\"labels\"]) for example in whisper_dataset[\"train\"]]\n",
        "\n",
        "# # Calculate the 95th percentile\n",
        "# percentile_95 = int(np.percentile(label_lengths, 95))\n",
        "# print(f\"95th percentile label length: {percentile_95}\")"
      ],
      "metadata": {
        "id": "z8vNPNKSwUYq"
      },
      "id": "z8vNPNKSwUYq",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_label = max(label_lengths)\n",
        "# print(f\"Max label length: {max_label}\")"
      ],
      "metadata": {
        "id": "ijzQhiFUw-Wa"
      },
      "id": "ijzQhiFUw-Wa",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the model"
      ],
      "metadata": {
        "id": "BuQLh_VYB6GD"
      },
      "id": "BuQLh_VYB6GD"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "25c4578f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25c4578f",
        "outputId": "5d304e45-dd0e-4310-f36a-d7c401871972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        }
      ],
      "source": [
        "# Define the name of the model once so it can be changed easily, if necessary\n",
        "model_name = \"openai/whisper-small\"\n",
        "# Load the model\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "# Get the processor\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "# Load the tokenizer\n",
        "tokenizer = processor.tokenizer\n",
        "tokenizer.pad_token = \"<|pad|>\"\n",
        "tokenizer.add_tokens([\"<|pad|>\"])\n",
        "model.config.pad_token_id = tokenizer.convert_tokens_to_ids(\"<|pad|>\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "# Load the feature extractor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name)\n",
        "# Create the processor with feature extractor and tokenizer\n",
        "processor = WhisperProcessor(\n",
        "    feature_extractor=feature_extractor,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "model.generation_config.task = \"transcribe\"\n",
        "model.generation_config.forced_decoder_ids = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "# Move the model to the GPU\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sluHyEX5S01",
        "outputId": "905c2c9b-ff25-47f7-8337-c6d0e1fcce18"
      },
      "id": "6sluHyEX5S01",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51866, 768, padding_idx=50257)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=768, out_features=51866, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d6d280",
      "metadata": {
        "id": "f6d6d280"
      },
      "source": [
        "### Create the data collator\n",
        "\n",
        "A data collator takes elements from the prepared datasets and creates batches for passing to the model. It also applies extra processing steps, like padding and masking here, to ensure that all the inputs are the same length.\n",
        "\n",
        "Note that `input_features` and `label_features` correspond to \"audio\" and text, respectively, in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8eb84a4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eb84a4e",
        "outputId": "30505c75-caf1-4cac-d032-59141c78ff37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum training steps: 942\n"
          ]
        }
      ],
      "source": [
        "# Define the custom DataCollator class\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # If the beginning of sentence (bos) token is appended in previous tokenization step,\n",
        "        # cut it, since it's append later anyways\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# Initialize the data collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")\n",
        "\n",
        "# Figure out the number of training steps\n",
        "num_train_samples = len(whisper_dataset[\"train\"])\n",
        "num_eval_samples = len(whisper_dataset[\"validation\"])\n",
        "recommended_max_steps = (num_train_samples // 16) * 3\n",
        "\n",
        "print(f\"Maximum training steps: {recommended_max_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Sample dummy processor + model for context (skip if you already have these)\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# Your custom collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")\n",
        "\n",
        "# Take a small subset of your dataset to test\n",
        "sample_batch = [whisper_dataset[\"train\"][i] for i in range(4)]\n",
        "\n",
        "# Run the collator\n",
        "batch = data_collator(sample_batch)\n",
        "\n",
        "# Inspect shapes and tensor values\n",
        "for k, v in batch.items():\n",
        "    print(f\"{k}: shape={v.shape}, dtype={v.dtype}\")\n",
        "\n",
        "# Optional: check if padding mask and labels match up\n",
        "print(\"\\nLabels (first example):\")\n",
        "print(batch[\"labels\"][0])\n",
        "print(\"\\nInput features (first example):\")\n",
        "print(batch[\"input_features\"][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgvR59fVcvlO",
        "outputId": "f20627d8-3964-428f-8a17-1329a287894e"
      },
      "id": "hgvR59fVcvlO",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_features: shape=torch.Size([4, 80, 3000]), dtype=torch.float32\n",
            "labels: shape=torch.Size([4, 12]), dtype=torch.int64\n",
            "\n",
            "Labels (first example):\n",
            "tensor([ 2330,   297, 18275,   514,   463,     6,    64,  -100,  -100,  -100,\n",
            "         -100,  -100])\n",
            "\n",
            "Input features (first example):\n",
            "torch.Size([80, 3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b94f6c",
      "metadata": {
        "id": "41b94f6c"
      },
      "source": [
        "### Define a custom `compute_metrics() function\n",
        "\n",
        "The best metric for an ASR model is Word Error Rate (WER), so the `compute_metrics()` function must focus on that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "57a6aa06",
      "metadata": {
        "id": "57a6aa06"
      },
      "outputs": [],
      "source": [
        "# Evaluation metric\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # Print shapes and a few values\n",
        "    print(\"pred_ids shape:\", pred_ids.shape)\n",
        "    print(\"label_ids shape:\", label_ids.shape)\n",
        "    print(\"First 10 pred_ids[0]:\", pred_ids[0][:10])\n",
        "    print(\"First 10 label_ids[0]:\", label_ids[0][:10])\n",
        "\n",
        "    # If pred_ids are logits (3D), take argmax\n",
        "    if len(pred_ids.shape) == 3:\n",
        "        print(\"Predictions appear to be logits. Taking argmax...\")\n",
        "        pred_ids = np.argmax(pred_ids, axis=-1)\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # Print decoded example\n",
        "    print(\"Decoded pred:\", tokenizer.decode(pred_ids[0], skip_special_tokens=True))\n",
        "    print(\"Decoded label:\", tokenizer.decode(label_ids[0], skip_special_tokens=True))\n",
        "\n",
        "    # Decode all predictions and references\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    print(\"First pred_str:\", pred_str[0])\n",
        "    print(\"First label_str:\", label_str[0])\n",
        "    print(\"Lengths:\", len(pred_str), len(label_str))\n",
        "\n",
        "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "637ea844",
      "metadata": {
        "id": "637ea844"
      },
      "source": [
        "### Define the model's settings\n",
        "\n",
        "The `training_args` variable holds many important settings that affect the outcome of the fine-tuning. The settings here are optimized for use when fine-tuning on a GPU.\n",
        "\n",
        "I'm going to explain the settings, even though they are [documented on Hugging Face](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments), since I want to be sure that I understand them. ðŸ¤“\n",
        "\n",
        "- `output_dir`: This is where the model's files will be stored. It was defined earlier in the notebook.\n",
        "- `per_device_train_batch_size`: The number of input and label pairs included per batch sent to the device (GPU) for training.\n",
        "- `per_device_eval_batch_size`: The number of input and label pairs included per batch sent to the device (GPU) for evaluation.\n",
        "- `gradient_accumulation_steps`: The trainer will perform a backward pass after two steps. The backward pass is part of the learning process, where the model makes adjustments based on what it has learned to that point.\n",
        "- `learning_rate`: This is the, well, learning rate for the optimizer. I have selected `1.25e-5` (i.e., 1.25 x 10 âˆ’ 5) as suggested at <https://github.com/vasistalodagala/whisper-finetune>\n",
        "- `warmup_steps`: The warmup process helps to avoid any big changes in the model's settings at the start of training.\n",
        "- `max_steps`: This is the number of steps that the training will last. I calculated it above by dividing the length of the training set by the number I'd select for the `per_device_train_batch_size`.\n",
        "- `eval_strategy`: The evaluation (WER) will be performed after the number of steps assigned in `eval_steps`.\n",
        "- `eval_steps`: This is calculated above by dividing the length of the validation set by the number assigned to `per_device_eval_batch_size`.\n",
        "- `save_steps`: How often the model will be saved. I'm saving as often as I evaluate.\n",
        "- `save_total_limit`: I don't want to fill up my space with checkpoints, so I'm setting it to 2.\n",
        "- `logging_steps`: How often information will be logged\n",
        "- `predict_with_generate`: This is set to `False` because I'm not using the model to generate text.\n",
        "- `report_to`: This will send the log data to Tensorboard, which is a nice way of visualizing the information.\n",
        "- `load_best_model_at_end`: This ensures that only the best model is loaded for saving.\n",
        "- `metric_for_best_model`: Defines Word Error Rate as the metric for determining the best model.\n",
        "- `greater_is_better`: This is set to false because a lower WER is better.\n",
        "- `fp16`: This is a performance boost. It tells the trainer to use 16-bit floating point numbers instead of the default 32-bit, which take longer to calculate.\n",
        "- `gradient_checkpointing`: Another performance boost by storing only a small number of checkpoints and recomputing during the backward pass.\n",
        "- `hub_model_id`: Identifies the model repo on Hugging Face Hub.\n",
        "- ` hub_strategy`: Set to `end` to push to the hub when the trainer has finished.\n",
        "- `push_to_hub`: Pushes the model to the hub at the end of the training.\n",
        "\n",
        "I have used steps instead of epochs because Whisper typically isn't trained for more than two or three epochs for a small dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f75b646c",
      "metadata": {
        "id": "f75b646c"
      },
      "outputs": [],
      "source": [
        "# # Define the training arguments\n",
        "# training_args = Seq2SeqTrainingArguments(\n",
        "#     output_dir=output_dir,                      # Output directory for model predictions and checkpoints\n",
        "#     per_device_train_batch_size=4,             # Batch size for training\n",
        "#     per_device_eval_batch_size=2,               # Batch size for evaluation\n",
        "#     gradient_accumulation_steps=2,              # Number of updates steps to accumulate before performing a backward/update pass\n",
        "#     learning_rate=1.25e-5,                      # Initial learning rate for the optimizer\n",
        "#     #warmup_steps=200,                           # Number of warmup steps for learning rate scheduler\n",
        "#     max_steps=max_steps,                        # Total number of training steps to perform\n",
        "#     eval_strategy=\"no\",                      # Evaluation strategy to adopt during training\n",
        "#     #eval_steps=500,                             # Number of steps between evaluations\n",
        "#     save_steps=500,                             # Number of steps between model saves\n",
        "#     save_total_limit=2,                         # Limit the total amount of checkpoints. Deletes the older checkpoints.\n",
        "#     logging_steps=25,                           # Number of steps between logging\n",
        "#     #predict_with_generate=False,                # Whether to use generate for predictions\n",
        "#     report_to=\"none\",                           # List of integrations to report the results\n",
        "#     #generation_max_length=64,                   # Maximum length of generated sequences\n",
        "#     #generation_num_beams=1,                     # Number of beams to use for generation\n",
        "#     #load_best_model_at_end=True,                # Load the best model when finished training\n",
        "#     #metric_for_best_model=\"wer\",                # Use word error rate (WER) to evaluate the best model\n",
        "#     #greater_is_better=False,                    # WER is lower when better, so we set this to False\n",
        "#     fp16=True,                                  # GPU: use FP16 for speed\n",
        "#     gradient_checkpointing=True,                # Helps with memory on GPU\n",
        "#     hub_model_id=\"sjhuskey/enenlhet-whisper\",   # Hugging Face Hub model ID\n",
        "#     hub_strategy=\"end\",                         # Hub strategy to use when pushing model\n",
        "#     push_to_hub=True,                           # Set to True if pushing model\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    run_name=\"enenlhet-whisper\",\n",
        "    output_dir=output_dir,  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=100,\n",
        "    max_steps=4710,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=65,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    eval_steps=200,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    hub_model_id=\"enenlhet-asr/enenlhet-whisper\",   # Hugging Face Hub model ID\n",
        "    hub_strategy=\"end\",                         # Hub strategy to use when pushing model\n",
        "    push_to_hub=True,                           # Set to True if pushing model\n",
        ")"
      ],
      "metadata": {
        "id": "6I6RhcWryE6H"
      },
      "id": "6I6RhcWryE6H",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "261d65b4",
      "metadata": {
        "id": "261d65b4"
      },
      "source": [
        "### Initialize the trainer\n",
        "\n",
        "The `trainer` gets some additional settings here, including the splits to use for training and testing. Note that most of the settings just point back to previously defined variables."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"spanish\", task=\"transcribe\")\n",
        "model.config.forced_decoder_ids = None"
      ],
      "metadata": {
        "id": "Z8NxL998zfGQ"
      },
      "id": "Z8NxL998zfGQ",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b4ff67fc",
      "metadata": {
        "id": "b4ff67fc"
      },
      "outputs": [],
      "source": [
        "# Initialize the trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=whisper_dataset[\"train\"],\n",
        "    eval_dataset=whisper_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b2b30b5",
      "metadata": {
        "id": "9b2b30b5"
      },
      "source": [
        "### Initialize an emissions tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9fa2349d",
      "metadata": {
        "id": "9fa2349d"
      },
      "outputs": [],
      "source": [
        "# tracker = EmissionsTracker(\n",
        "#     project_name=\"whisper-enenlhet-gpu\",\n",
        "#     output_dir=log_dir,\n",
        "#     output_file=\"whisper-emissions-gpu.csv\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1930ab57",
      "metadata": {
        "id": "1930ab57"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "I have wrapped the training step in `try` and `except` to handle the seemingly inevitable problems that crop up at this stage. If all went well with the previous steps, the model should start training. If not, then debugging is the name of the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "8e54e2ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a24b0a7117414dbeada050d9a27d5afc",
            "4e61d0a8f062415793e1c939db3b7d14",
            "a90f9fefb7d1439db56a0fba5655ca41",
            "f9221fc296074947bdf6756bae7c420a",
            "29d15f4a7c744d04ac7e543be69ff7db",
            "a2d7144db1f24b549ff864583ef9ca76",
            "14743b1e08d6423fa22051357754c531",
            "d4dd181f57c743db87e88f238eb6f70f",
            "8bf94bf248ba445d80155ce27ad2486c",
            "8f53ac85fa0b4a979163989f9a169ab6",
            "643d8b44ae4641b18e5d4914dc0d22c0"
          ]
        },
        "id": "8e54e2ff",
        "outputId": "3ebafcbf-1a05-4ff1-cbfb-cbb933aecff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting emissions tracking...\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1400' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1400/4710 1:48:06 < 4:15:57, 0.22 it/s, Epoch 4/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.836200</td>\n",
              "      <td>4.636086</td>\n",
              "      <td>433.616384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.284100</td>\n",
              "      <td>3.343280</td>\n",
              "      <td>701.998002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.948800</td>\n",
              "      <td>3.113490</td>\n",
              "      <td>489.010989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.667800</td>\n",
              "      <td>3.076094</td>\n",
              "      <td>401.848152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.203300</td>\n",
              "      <td>3.024310</td>\n",
              "      <td>516.783217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.221700</td>\n",
              "      <td>2.991132</td>\n",
              "      <td>562.187812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.934800</td>\n",
              "      <td>3.058273</td>\n",
              "      <td>410.689311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [  297   304    71  1501   330   287    71  1857 31494   287]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  nalhengke lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  nalhengke lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga lhennenga\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [ 2012  1301     6   514  1641 17342  1301     6   514 31332]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  Amai'akha svai'ak kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  Amai'akha svai'ak kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha kelha\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [2012 1301    6  514 1641  262 9771  514    6  514]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  Amai'akha svetak'ak, kaktema nak nengke'e' nengvetai'a, Amai'akha stak'a, nengke'e' nengke'e'n, nengke'e'n, n\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  Amai'akha svetak'ak, kaktema nak nengke'e' nengvetai'a, Amai'akha stak'a, nengke'e' nengke'e'n, nengke'e'n, n\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [  287 39903   220   220   220   220   220   220   220   220]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  lhta                                                           \n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  lhta                                                           \n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [3374   11 3374   11 3374   11 3374   11 3374   11]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [  287 39903   220   656 33754   287   675   220   656 33754]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  lhta angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok l\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  lhta angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok lhe angkok l\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [3374   11 3374   11 3374   11 3374   11 3374   11]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America\n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America, America\n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training completed successfully!\n",
            " Final training loss: 3.3636\n",
            " Total training steps: 1400\n",
            "\n",
            " Running final evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [79/79 03:58]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_ids shape: (630, 448)\n",
            "label_ids shape: (630, 448)\n",
            "First 10 pred_ids[0]: [  287 39903   220   220   220   220   220   220   220   220]\n",
            "First 10 label_ids[0]: [   77  1684 23255 20332   364  2918     6    64  -100  -100]\n",
            "Decoded pred:  lhta                                                           \n",
            "Decoded label: nietnek nak aniam'a\n",
            "First pred_str:  lhta                                                           \n",
            "First label_str: nietnek nak aniam'a\n",
            "Lengths: 630 630\n",
            "Final WER: 401.8482\n",
            "Saving final model to ./enenlhet-whisper-model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a24b0a7117414dbeada050d9a27d5afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and saving completed successfully!\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "try:\n",
        "    # Start emissions tracking\n",
        "    print(\"Starting emissions tracking...\")\n",
        "    # tracker.start()\n",
        "    # Train the model\n",
        "    print(\"Starting training...\")\n",
        "    train_result = trainer.train()\n",
        "    # Stop emissions tracking\n",
        "    # tracker.stop()\n",
        "    print(\"\\n Training completed successfully!\")\n",
        "    print(f\" Final training loss: {train_result.training_loss:.4f}\")\n",
        "    print(f\" Total training steps: {train_result.global_step}\")\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\n Running final evaluation...\")\n",
        "    eval_result = trainer.evaluate()\n",
        "    print(f\"Final WER: {eval_result['eval_wer']:.4f}\")\n",
        "\n",
        "    # Save final model\n",
        "    print(f\"Saving final model to {training_args.output_dir}\")\n",
        "    trainer.save_model()\n",
        "    processor.save_pretrained(training_args.output_dir)\n",
        "\n",
        "    print(\"Training and saving completed successfully!\")\n",
        "\n",
        "# If nothing went as planned â€¦\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining failed with error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # Still try to save current model state\n",
        "    print(\"ðŸ’¾ Attempting to save current model state...\")\n",
        "    try:\n",
        "        trainer.save_model()\n",
        "        processor.save_pretrained(training_args.output_dir)\n",
        "        print(\"Model saved despite training error\")\n",
        "    except:\n",
        "        print(\"Could not save model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bjpp1M1D-mUf"
      },
      "id": "Bjpp1M1D-mUf",
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d251704da7eb483aa7c3b7a6a65d07e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612960362b3040c3888c34a02f79b485",
              "IPY_MODEL_18d0ddebc22c42d984011e7bd5f586ca",
              "IPY_MODEL_16a5184995244501a5af53654ac1023f",
              "IPY_MODEL_a63ed8d1ce80420dbb1a40933346b1db",
              "IPY_MODEL_ffadd20e604a4a94b6b55b77f8a11f5f"
            ],
            "layout": "IPY_MODEL_b8ff8e3a255b40e7971c63e4fd6f4426"
          }
        },
        "612960362b3040c3888c34a02f79b485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3919b5b6ac684c8ea3344fed966f3718",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fe6598d93de4429d810b0a5adbc864b9",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "18d0ddebc22c42d984011e7bd5f586ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f7269a56b17c456f995be215718b8fed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a3c4bad0fbd6405f804a64a4bfe01899",
            "value": ""
          }
        },
        "16a5184995244501a5af53654ac1023f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_64acfdfac90d4146a9d8843d5f21cda3",
            "style": "IPY_MODEL_e3b40c7086d341658d3b6f6939f34aef",
            "value": true
          }
        },
        "a63ed8d1ce80420dbb1a40933346b1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cf86c92da8f141098d03804b9d6c9185",
            "style": "IPY_MODEL_524e1f736bd84a25bc226f94f5aab279",
            "tooltip": ""
          }
        },
        "ffadd20e604a4a94b6b55b77f8a11f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90dc5091affe44aaaf8a411eebe66e3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a8c9e0743a84443a8780787501e5daa",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b8ff8e3a255b40e7971c63e4fd6f4426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3919b5b6ac684c8ea3344fed966f3718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6598d93de4429d810b0a5adbc864b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7269a56b17c456f995be215718b8fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c4bad0fbd6405f804a64a4bfe01899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64acfdfac90d4146a9d8843d5f21cda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b40c7086d341658d3b6f6939f34aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf86c92da8f141098d03804b9d6c9185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524e1f736bd84a25bc226f94f5aab279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "90dc5091affe44aaaf8a411eebe66e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8c9e0743a84443a8780787501e5daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a24b0a7117414dbeada050d9a27d5afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e61d0a8f062415793e1c939db3b7d14",
              "IPY_MODEL_a90f9fefb7d1439db56a0fba5655ca41",
              "IPY_MODEL_f9221fc296074947bdf6756bae7c420a"
            ],
            "layout": "IPY_MODEL_29d15f4a7c744d04ac7e543be69ff7db"
          }
        },
        "4e61d0a8f062415793e1c939db3b7d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d7144db1f24b549ff864583ef9ca76",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14743b1e08d6423fa22051357754c531",
            "value": "Uploading...:â€‡100%"
          }
        },
        "a90f9fefb7d1439db56a0fba5655ca41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4dd181f57c743db87e88f238eb6f70f",
            "max": 967067905,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bf94bf248ba445d80155ce27ad2486c",
            "value": 967067905
          }
        },
        "f9221fc296074947bdf6756bae7c420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f53ac85fa0b4a979163989f9a169ab6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_643d8b44ae4641b18e5d4914dc0d22c0",
            "value": "â€‡967M/967Mâ€‡[00:10&lt;00:00,â€‡113MB/s]"
          }
        },
        "29d15f4a7c744d04ac7e543be69ff7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d7144db1f24b549ff864583ef9ca76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14743b1e08d6423fa22051357754c531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4dd181f57c743db87e88f238eb6f70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf94bf248ba445d80155ce27ad2486c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f53ac85fa0b4a979163989f9a169ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643d8b44ae4641b18e5d4914dc0d22c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}